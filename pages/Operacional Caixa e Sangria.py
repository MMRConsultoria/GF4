import streamlit as st
import pandas as pd
import numpy as np
import json
from io import BytesIO
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from gspread_formatting import format_cell_range, CellFormat, NumberFormat




st.set_page_config(page_title="Relat√≥rio de Sangria", layout="wide")
# üî• CSS para estilizar as abas
st.markdown("""
    <style>
    .stApp { background-color: #f9f9f9; }
    div[data-baseweb="tab-list"] { margin-top: 20px; }
    button[data-baseweb="tab"] {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 10px 20px;
        margin-right: 10px;
        transition: all 0.3s ease;
        font-size: 16px;
        font-weight: 600;
    }
    button[data-baseweb="tab"]:hover { background-color: #dce0ea; color: black; }
    button[data-baseweb="tab"][aria-selected="true"] { background-color: #0366d6; color: white; }
    </style>
""", unsafe_allow_html=True)

# üîí Bloqueio
if not st.session_state.get("acesso_liberado"):
    st.stop()

# üîï Oculta toolbar
st.markdown("""
    <style>
        [data-testid="stToolbar"] { visibility: hidden; height: 0%; position: fixed; }
        .stSpinner { visibility: visible !important; }
    </style>
""", unsafe_allow_html=True)

NOME_SISTEMA = "Colibri"

# -----------------------
# Helpers
# -----------------------
def auto_read_first_or_sheet(uploaded, preferred="Sheet"):
    """L√™ a guia 'preferred' se existir; sen√£o, l√™ a primeira guia."""
    xls = pd.ExcelFile(uploaded)
    sheets = xls.sheet_names
    sheet_to_read = preferred if preferred in sheets else sheets[0]
    df0 = pd.read_excel(xls, sheet_name=sheet_to_read)
    return df0, sheet_to_read, sheets

def normalize_dates(s):
    """Para comparar datas (remove hor√°rio)."""
    return pd.to_datetime(s, errors="coerce", dayfirst=True).dt.normalize()

with st.spinner("‚è≥ Processando..."):
    # üîå Conex√£o Google Sheets
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    credentials_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    credentials = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
    gc = gspread.authorize(credentials)
    planilha = gc.open("Vendas diarias")

    df_empresa = pd.DataFrame(planilha.worksheet("Tabela Empresa").get_all_records())
    ws_tab = planilha.worksheet("Tabela Sangria")
    dados = ws_tab.get_all_records()  # l√™ usando a primeira linha como cabe√ßalho
    df_descricoes = pd.DataFrame(dados)
    # Garante as colunas
    df_descricoes.columns = [c.strip() for c in df_descricoes.columns]
    if not {"Palavra-chave", "Descri√ß√£o Agrupada"}.issubset(df_descricoes.columns):
        st.error("A aba 'Tabela Sangria' precisa ter as colunas 'Palavra-chave' e 'Descri√ß√£o Agrupada'.")
        st.stop()

    # üî• T√≠tulo
    st.markdown("""
        <div style='display: flex; align-items: center; gap: 10px;'>
            <img src='https://img.icons8.com/color/48/graph.png' width='40'/>
            <h1 style='display: inline; margin: 0; font-size: 2.4rem;'>Controle de Caixa e Sangria</h1>
        </div>
    """, unsafe_allow_html=True)

    # üóÇÔ∏è Abas
    tab1, tab2 = st.tabs(["üì• Upload e Processamento", "üîÑ Atualizar Google Sheets"])

    # ================
    # üì• Aba 1 ‚Äî Upload e Processamento (detec√ß√£o Colibri √ó Everest)
    # ================
    with tab1:
        uploaded_file = st.file_uploader(
            label="üìÅ Clique para selecionar ou arraste aqui o arquivo Excel",
            type=["xlsx", "xlsm"],
            help="Somente arquivos .xlsx ou .xlsm. Tamanho m√°ximo: 200MB."
        )
    
        if uploaded_file:
            def auto_read_first_or_sheet(uploaded, preferred="Sheet"):
                xls = pd.ExcelFile(uploaded)
                sheets = xls.sheet_names
                sheet_to_read = preferred if preferred in sheets else sheets[0]
                df0 = pd.read_excel(xls, sheet_name=sheet_to_read)
                df0.columns = [str(c).strip() for c in df0.columns]
                return df0, sheet_to_read, sheets
    
            try:
                df_dados, guia_lida, lista_guias = auto_read_first_or_sheet(uploaded_file, preferred="Sheet")
                #st.caption(f"Guia lida: **{guia_lida}** (dispon√≠veis: {', '.join(lista_guias)})")
            except Exception as e:
                st.error(f"‚ùå N√£o foi poss√≠vel ler o arquivo enviado. Detalhes: {e}")
            else:
                df = df_dados.copy()
                primeira_col = df.columns[0] if len(df.columns) else ""
                is_everest = primeira_col.lower() in ["lan√ßamento", "lancamento"] or ("Lan√ßamento" in df.columns) or ("Lancamento" in df.columns)
    
                if is_everest:

                    # ---------------- MODO EVEREST ----------------
                    st.session_state.mode = "everest"
                    st.session_state.df_everest = df.copy()
                
                    import unicodedata, re
                    def _norm(s: str) -> str:
                        s = unicodedata.normalize('NFKD', str(s)).encode('ASCII','ignore').decode('ASCII')
                        s = s.lower()
                        s = re.sub(r'[^a-z0-9]+', ' ', s)
                        return re.sub(r'\s+', ' ', s).strip()
                
                    # 1) DATA => "D. Lan√ßamento" (varia√ß√µes)
                    date_col = None
                    for cand in ["D. Lan√ßamento", "D.Lan√ßamento", "D. Lancamento", "D.Lancamento"]:
                        if cand in df.columns:
                            date_col = cand
                            break
                    if date_col is None:
                        for col in df.columns:
                            if _norm(col) in ["d lancamento", "data lancamento", "d lancamento data"]:
                                date_col = col
                                break
                    st.session_state.everest_date_col = date_col
                
                    # 2) VALOR => "Valor Lan√ßamento" (varia√ß√µes) com fallback seguro
                    def detect_valor_col(_df, avoid_col=None):
                        aliases = [
                            "valor lancamento", "valor lan√ßamento",
                            "valor do lancamento", "valor de lancamento",
                            "valor do lan√ßamento", "valor de lan√ßamento",
                            "valor"
                        ]
                        # preferir match por nome normalizado (exato)
                        targets = {a: _norm(a) for a in aliases}
                        for c in _df.columns:
                            if c == avoid_col: 
                                continue
                            if _norm(c) in targets.values():
                                return c
                        # fallback: escolher coluna (‚â† data) com mais c√©lulas contendo d√≠gitos
                        best, score = None, -1
                        for c in _df.columns:
                            if c == avoid_col: 
                                continue
                            sc = _df[c].astype(str).str.contains(r"\d").sum()
                            if sc > score:
                                best, score = c, sc
                        return best
                
                    valor_col = detect_valor_col(df, avoid_col=date_col)
                    st.session_state.everest_value_col = valor_col
                    # Conversor pt-BR robusto: R$, par√™nteses, sinal no final (1.234,56-)
                    def to_number_br(series):
                        def _one(x):
                            if pd.isna(x):
                                return 0.0
                            s = str(x).strip()
                            if s == "":
                                return 0.0
                            neg = False
                            # par√™nteses => negativo
                            if s.startswith("(") and s.endswith(")"):
                                neg = True
                                s = s[1:-1].strip()
                            # remove R$
                            s = s.replace("R$", "").replace("r$", "").strip()
                            # sinal no final (ex.: 1.234,56-)
                            if s.endswith("-"):
                                neg = True
                                s = s[:-1].strip()
                            # separadores pt-BR
                            s = s.replace(".", "").replace(",", ".")
                            s_clean = re.sub(r"[^0-9.\-]", "", s)
                            if s_clean in ["", "-", "."]:
                                return 0.0
                            try:
                                val = float(s_clean)
                            except:
                                s_fallback = re.sub(r"[^0-9.]", "", s_clean)
                                val = float(s_fallback) if s_fallback else 0.0
                            return -abs(val) if neg else val
                        return series.apply(_one)
                
                    # 3) M√©tricas
                    periodo_txt = "‚Äî"
                    total_txt = "‚Äî"
                
                    # Per√≠odo a partir de D. Lan√ßamento
                    if date_col is not None:
                        dt = pd.to_datetime(df[date_col], errors="coerce", dayfirst=True)
                        valid = dt.dropna()
                        if not valid.empty:
                            periodo_min = valid.min().strftime("%d/%m/%Y")
                            periodo_max = valid.max().strftime("%d/%m/%Y")
                            periodo_txt = f"{periodo_min} at√© {periodo_max}"
                            st.session_state.everest_dates = valid.dt.normalize().unique().tolist()
                        else:
                            st.warning("‚ö†Ô∏è A coluna 'D. Lan√ßamento' existe, mas n√£o tem datas v√°lidas.")
                    else:
                        st.error("‚ùå N√£o encontrei a coluna **'D. Lan√ßamento'**.")
                
                    # Total pela coluna de valor (preservando o sinal real)
                    if valor_col is not None:
                        if pd.api.types.is_numeric_dtype(df[valor_col]):
                            serie_val = pd.to_numeric(df[valor_col], errors="coerce").fillna(0.0)
                        else:
                            serie_val = to_number_br(df[valor_col])
                        total_liquido = float(serie_val.sum())
                        st.session_state.everest_total_liquido = total_liquido
                
                        sinal = "-" if total_liquido < 0 else ""
                        total_fmt = f"{abs(total_liquido):,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
                        total_txt = f"{sinal}R$ {total_fmt}"
                    else:
                        st.warning("‚ö†Ô∏è N√£o encontrei a coluna de **valor** (ex.: 'Valor Lan√ßamento').")
                
                    # 4) M√©tricas (sem preview)
                    if periodo_txt != "‚Äî":
                        c1, c2, c3 = st.columns(3)
                        c1.metric("üìÖ Per√≠odo processado", periodo_txt)
                        #c2.metric("üßæ Linhas lidas", f"{len(df)}")
                        c3.metric("üí∞ Total (Valor Lan√ßamento)", total_txt)
                    else:
                        c1, c2 = st.columns(2)
                        #c1.metric("üßæ Linhas lidas", f"{len(df)}")
                        c2.metric("üí∞ Total (Valor Lan√ßamento)", total_txt)
                
                    # 5) Download do arquivo como veio
                    output_ev = BytesIO()
                    with pd.ExcelWriter(output_ev, engine="openpyxl") as writer:
                        df.to_excel(writer, index=False, sheet_name="Sangria Everest")
                    output_ev.seek(0)
                    st.download_button(
                        "üì• Sangria Everest",
                        data=output_ev,
                        file_name="Sangria_Everest.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

    
                else:
                    # ---------------- MODO COLIBRI (seu fluxo atual) ----------------
                    try:
                        df["Loja"] = np.nan
                        df["Data"] = np.nan
                        df["Funcion√°rio"] = np.nan
    
                        data_atual = None
                        funcionario_atual = None
                        loja_atual = None
                        linhas_validas = []
    
                        for i, row in df.iterrows():
                            valor = str(row["Hora"]).strip()
                            if valor.startswith("Loja:"):
                                loja = valor.split("Loja:")[1].split("(Total")[0].strip()
                                if "-" in loja:
                                    loja = loja.split("-", 1)[1].strip()
                                loja_atual = loja or "Loja n√£o cadastrada"
                            elif valor.startswith("Data:"):
                                try:
                                    data_atual = pd.to_datetime(
                                        valor.split("Data:")[1].split("(Total")[0].strip(), dayfirst=True
                                    )
                                except Exception:
                                    data_atual = pd.NaT
                            elif valor.startswith("Funcion√°rio:"):
                                funcionario_atual = valor.split("Funcion√°rio:")[1].split("(Total")[0].strip()
                            else:
                                if pd.notna(row["Valor(R$)"]) and pd.notna(row["Hora"]):
                                    df.at[i, "Data"] = data_atual
                                    df.at[i, "Funcion√°rio"] = funcionario_atual
                                    df.at[i, "Loja"] = loja_atual
                                    linhas_validas.append(i)
    
                        df = df.loc[linhas_validas].copy()
                        df.ffill(inplace=True)
                        # ===== FIX: preencher Descri√ß√£o quando Hora √© hor√°rio e Valor(R$) est√° preenchido =====
                        def _is_blank(series: pd.Series) -> pd.Series:
                            s = series.astype(str).str.strip().str.lower()
                            return series.isna() | s.isin(["", "nan", "none", "null"])
                        
                        # Hora v√°lida: tenta converter para hor√°rio (ou timestamp) ‚Üí n√£o NaT
                        mask_hora_valida = pd.to_datetime(df["Hora"], errors="coerce").notna()
                        
                        # Valor(R$) preenchido (qualquer coisa diferente de vazio/NAN/NONE)
                        mask_valor_preenchido = ~_is_blank(df["Valor(R$)"])
                        
                        # Descri√ß√£o vazia
                        mask_desc_vazia = _is_blank(df["Descri√ß√£o"])
                        
                        # Aplica a regra
                        df.loc[mask_hora_valida & mask_valor_preenchido & mask_desc_vazia, "Descri√ß√£o"] = "sem preenchimento"
                        # =======================================================================

                        # Limpeza e convers√µes
                        df["Descri√ß√£o"] = (
                            df["Descri√ß√£o"].astype(str).str.strip().str.lower().str.replace(r"\s+", " ", regex=True)
                        )
                        df["Funcion√°rio"] = df["Funcion√°rio"].astype(str).str.strip()
                        df["Valor(R$)"] = pd.to_numeric(df["Valor(R$)"], errors="coerce").fillna(0.0).round(2)
    
                        # Dia semana / m√™s / ano
                        dias_semana = {0: 'segunda-feira', 1: 'ter√ßa-feira', 2: 'quarta-feira',
                                       3: 'quinta-feira', 4: 'sexta-feira', 5: 's√°bado', 6: 'domingo'}
                        df["Dia da Semana"] = df["Data"].dt.dayofweek.map(dias_semana)
                        df["M√™s"] = df["Data"].dt.month.map({
                            1: 'jan', 2: 'fev', 3: 'mar', 4: 'abr', 5: 'mai', 6: 'jun',
                            7: 'jul', 8: 'ago', 9: 'set', 10: 'out', 11: 'nov', 12: 'dez'
                        })
                        df["Ano"] = df["Data"].dt.year
                        df["Data"] = df["Data"].dt.strftime("%d/%m/%Y")
    
                        # Merge com cadastro de lojas
                        df["Loja"] = df["Loja"].astype(str).str.strip().str.lower()
                        df_empresa["Loja"] = df_empresa["Loja"].astype(str).str.strip().str.lower()
                        df = pd.merge(df, df_empresa, on="Loja", how="left")
    
                        # Agrupamento de descri√ß√£o
                        def mapear_descricao(desc):
                            desc_lower = str(desc).lower()
                            for _, r in df_descricoes.iterrows():
                                if str(r["Palavra-chave"]).lower() in desc_lower:
                                    return r["Descri√ß√£o Agrupada"]
                            return "Outros"
    
                        df["Descri√ß√£o Agrupada"] = df["Descri√ß√£o"].apply(mapear_descricao)
    
                        # ‚ûï Colunas adicionais
                        df["Sistema"] = NOME_SISTEMA
    
                        # üîë DUPLICIDADE
                        data_key = pd.to_datetime(df["Data"], dayfirst=True, errors="coerce").dt.strftime("%Y-%m-%d")
                        hora_key = pd.to_datetime(df["Hora"], errors="coerce").dt.strftime("%H:%M:%S")
                        valor_centavos = (df["Valor(R$)"].astype(float) * 100).round().astype(int).astype(str)
                        desc_key = df["Descri√ß√£o"].fillna("").astype(str)
                        df["Duplicidade"] = (
                            data_key.fillna("") + "|" +
                            hora_key.fillna("") + "|" +
                            df["C√≥digo Everest"].fillna("").astype(str) + "|" +
                            valor_centavos + "|" +
                            desc_key
                        )
    
                        if "Meio de recebimento" not in df.columns:
                            df["Meio de recebimento"] = ""
    
                        colunas_ordenadas = [
                            "Data", "Dia da Semana", "Loja", "C√≥digo Everest", "Grupo",
                            "C√≥digo Grupo Everest", "Funcion√°rio", "Hora", "Descri√ß√£o",
                            "Descri√ß√£o Agrupada", "Meio de recebimento", "Valor(R$)",
                            "M√™s", "Ano", "Duplicidade", "Sistema"
                        ]
                        df = df[colunas_ordenadas].sort_values(by=["Data", "Loja"])
    
                        # M√©tricas
                        periodo_min = pd.to_datetime(df["Data"], dayfirst=True).min().strftime("%d/%m/%Y")
                        periodo_max = pd.to_datetime(df["Data"], dayfirst=True).max().strftime("%d/%m/%Y")
                        valor_total = float(df["Valor(R$)"].sum())
    
                        col1, col2 = st.columns(2)
                        col1.metric("üìÖ Per√≠odo processado", f"{periodo_min} at√© {periodo_max}")
                        col2.metric(
                            "üí∞ Valor total de sangria",
                            f"R$ {valor_total:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
                        )
    
                        st.success("‚úÖ Relat√≥rio gerado com sucesso!")
    
                        lojas_sem_codigo = df[df["C√≥digo Everest"].isna()]["Loja"].unique()
                        if len(lojas_sem_codigo) > 0:
                            st.warning(
                                f"‚ö†Ô∏è Lojas sem C√≥digo Everest cadastrado: {', '.join(lojas_sem_codigo)}\n\n"
                                "üîó Atualize na planilha de empresas."
                            )
    
                        # Guarda para a Tab2 (fluxo antigo)
                        st.session_state.mode = "colibri"
                        st.session_state.df_sangria = df.copy()
    
                        # Download Excel local (sem formata√ß√£o especial)
                        # --- ORDENAR por Data antes do download local (Colibri) ---
                        df_download = df.copy()
                        
                        # A coluna "Data" no fluxo Colibri j√° est√° como string dd/mm/aaaa.
                        # Vamos criar uma coluna auxiliar datetime para ordenar corretamente.
                        df_download["_Data_dt"] = pd.to_datetime(df_download["Data"], dayfirst=True, errors="coerce")
                        
                        # Se quiser desempatar por loja dentro do dia, use: by=["_Data_dt","Loja"]
                        df_download = df_download.sort_values(by=["_Data_dt"]).drop(columns=["_Data_dt"])
                        
                        # Gera o Excel j√° ordenado
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine="openpyxl") as writer:
                            df_download.to_excel(writer, index=False, sheet_name="Sangria")
                        output.seek(0)
                        
                        st.download_button("üì•Sangria Colibri",
                                           data=output,
                                           file_name="Sangria_estruturada.xlsx",
                                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

                    except KeyError as e:
                        st.error(f"‚ùå Coluna obrigat√≥ria ausente para o padr√£o Colibri: {e}")


    # ================
    # üîÑ Aba 2 ‚Äî Atualizar Google Sheets (Sangria √ó Sangria Everest)
    # ================
    with tab2:
        st.markdown("üîó [Abrir planilha Vendas diarias](https://docs.google.com/spreadsheets/d/1AVacOZDQT8vT-E8CiD59IVREe3TpKwE_25wjsj--qTU)")
        from gspread_formatting import format_cell_range, CellFormat, NumberFormat

        # Formato cont√°bil com s√≠mbolo R$ (positivo; negativo entre par√™nteses; zero como "-"; texto)
        ACCOUNTING_RS = CellFormat(
            numberFormat=NumberFormat(
                type="CURRENCY",
                pattern="R$ * #,##0.00_);R$ * (#,##0.00);R$ * -_;@"
            )
        )

        # ‚úÖ defina o mode ANTES de us√°-lo
        mode = st.session_state.get("mode", None)
        def _excel_col_letter(idx_zero_based: int) -> str:
            """Converte √≠ndice 0-based em letra de coluna (A..Z, AA..)."""
            n = idx_zero_based + 1
            s = ""
            while n:
                n, r = divmod(n - 1, 26)
                s = chr(65 + r) + s
            return s

        # --- modo Everest: substituir apenas as datas presentes no arquivo e enviar valor com v√≠rgula ---
        # --- MODO EVEREST: remover s√≥ as datas do arquivo; inserir novas; formatar valores com v√≠rgula/2 casas ---
        if mode == "everest" and "df_everest" in st.session_state:
            df_file = st.session_state.df_everest.copy()
        
            import re, unicodedata
        
            def _norm(s: str) -> str:
                s = unicodedata.normalize('NFKD', str(s)).encode('ASCII','ignore').decode('ASCII')
                s = s.lower()
                s = re.sub(r'[^a-z0-9]+', ' ', s)
                return re.sub(r'\s+', ' ', s).strip()
        
            # Detecta colunas no ARQUIVO
            date_file_col = st.session_state.get("everest_date_col")
            if not date_file_col or date_file_col not in df_file.columns:
                for cand in ["D. Lan√ßamento", "D.Lan√ßamento", "D. Lancamento", "D.Lancamento"]:
                    if cand in df_file.columns:
                        date_file_col = cand
                        break
            if not date_file_col or date_file_col not in df_file.columns:
                st.error("‚ùå Para atualizar a aba **Sangria Everest**, preciso da coluna **'D. Lan√ßamento'** no arquivo.")
                st.stop()
        
            # Detecta colunas de valor no ARQUIVO
            def detect_valor_col(cols):
                aliases = {
                    "valor lancamento", "valor lan√ßamento",
                    "valor do lancamento", "valor de lancamento",
                    "valor do lan√ßamento", "valor de lan√ßamento"
                }
                for c in cols:
                    if _norm(c) in aliases:
                        return c
                return None
        
            def detect_rateio_col(cols):
                aliases = {"v rateio", "v. rateio", "valor rateio"}
                for c in cols:
                    if _norm(c) in aliases:
                        return c
                return None
        
            valor_file_col  = detect_valor_col(df_file.columns)
            rateio_file_col = detect_rateio_col(df_file.columns)
        
            # Conversor robusto pt-BR ‚Üí n√∫mero
            def to_number_br(series):
                def _one(x):
                    if pd.isna(x): return 0.0
                    s = str(x).strip()
                    if s == "": return 0.0
                    neg = False
                    if s.startswith("(") and s.endswith(")"):
                        neg = True; s = s[1:-1].strip()
                    s = s.replace("R$", "").replace("r$", "").strip()
                    if s.endswith("-"):
                        neg = True; s = s[:-1].strip()
                    s = s.replace(".", "").replace(",", ".")
                    s_clean = re.sub(r"[^0-9.\-]", "", s)
                    if s_clean in ["", "-", "."]: return 0.0
                    try:
                        val = float(s_clean)
                    except:
                        s_fallback = re.sub(r"[^0-9.]", "", s_clean)
                        val = float(s_fallback) if s_fallback else 0.0
                    return -abs(val) if neg else val
                return series.apply(_one)
        
            # ‚ñ∂Ô∏è Datas como STRING dd/mm/aaaa (aceita texto e serial Excel)
            def date_to_str(series):
                def _parse_one(x):
                    if pd.isna(x): return ""
                    s = str(x).strip()
                    if s == "": return ""
                    # n√∫mero/float ‚Üí serial Excel (sistema 1900)
                    if re.fullmatch(r"\d+([.,]\d+)?", s):
                        try:
                            f = float(s.replace(",", "."))
                            dt = pd.Timestamp("1899-12-30") + pd.to_timedelta(f, unit="D")
                            return dt.strftime("%d/%m/%Y")
                        except Exception:
                            pass
                    # tenta dd/mm/aaaa etc. (dayfirst) e ISO
                    dt = pd.to_datetime(s, dayfirst=True, errors="coerce")
                    if pd.isna(dt):
                        dt = pd.to_datetime(s, errors="coerce")
                    return "" if pd.isna(dt) else dt.strftime("%d/%m/%Y")
                return series.apply(_parse_one)
        
            # Conjunto de datas do ARQUIVO (strings dd/mm/aaaa)
            file_dates_str = set([d for d in date_to_str(df_file[date_file_col]).tolist() if d])
        
            if not file_dates_str:
                st.error("‚ùå A coluna **'D. Lan√ßamento'** do arquivo n√£o possui datas v√°lidas.")
                st.stop()
        
            # Abre a aba destino
            try:
                ws = planilha.worksheet("Sangria Everest")
            except Exception as e:
                st.error(f"‚ùå N√£o consegui abrir a aba 'Sangria Everest': {e}")
                st.stop()
        
            rows = ws.get_all_values()
            if not rows:
                # planilha vazia ‚Üí escreve arquivo j√° formatando
                header_sheet = list(df_file.columns)
                df_insert = df_file.copy()
                # Data do arquivo como dd/mm/aaaa para manter consist√™ncia
                df_insert[date_file_col] = date_to_str(df_insert[date_file_col])
        
                def to_str_comma(series_like):
                    if pd.api.types.is_numeric_dtype(series_like):
                        nums = pd.to_numeric(series_like, errors="coerce").fillna(0.0)
                    else:
                        nums = to_number_br(series_like)
                    return nums.apply(lambda v: f"{float(v):.2f}".replace(".", ","))
        
                if valor_file_col and valor_file_col in df_insert.columns:
                    df_insert[valor_file_col] = to_str_comma(df_insert[valor_file_col])
                if rateio_file_col and rateio_file_col in df_insert.columns:
                    df_insert[rateio_file_col] = to_str_comma(df_insert[rateio_file_col])
        
                values = [header_sheet] + df_insert.fillna("").astype(str).values.tolist()
                ws.clear()

                ws.update("A1", values, value_input_option="USER_ENTERED")
                
                # ‚¨áÔ∏è ADICIONE ESTE TRECHO
                # Descobre as colunas "Valor Lan√ßamento" e "V. Rateio" pelo cabe√ßalho
                valor_sheet_col  = None
                rateio_sheet_col = None
                for c in header_sheet:
                    if _norm(c) in {"valor lancamento", "valor lan√ßamento",
                                    "valor do lancamento", "valor de lancamento",
                                    "valor do lan√ßamento", "valor de lan√ßamento"}:
                        valor_sheet_col = c
                    if _norm(c) in {"v rateio", "v. rateio", "valor rateio"}:
                        rateio_sheet_col = c
                
                last_row = 1 + len(df_insert)  # 1 (cabe√ßalho) + linhas de dados
                if valor_sheet_col:
                    col_letter = _excel_col_letter(header_sheet.index(valor_sheet_col))
                    format_cell_range(ws, f"{col_letter}2:{col_letter}{last_row}", ACCOUNTING_RS)
                if rateio_sheet_col:
                    col_letter = _excel_col_letter(header_sheet.index(rateio_sheet_col))
                    format_cell_range(ws, f"{col_letter}2:{col_letter}{last_row}", ACCOUNTING_RS)
                # ‚¨ÜÔ∏è FIM DO TRECHO
                
                # (j√° existente)
                st.success(f"‚úÖ 'Sangria Everest' criada com {len(df_insert)} linhas.")
                st.balloons()
                st.stop()

                
                
                
                
                
                st.success(f"‚úÖ 'Sangria Everest' criada com {len(df_insert)} linhas.")
                st.balloons()
                st.stop()
        
            # J√° existe conte√∫do no sheet ‚Üí REMOVER APENAS AS DATAS DO ARQUIVO e inserir as novas
            header_sheet = rows[0]
            data_sheet   = rows[1:]
            df_sheet     = pd.DataFrame(data_sheet, columns=header_sheet)
        
            # Detecta coluna de data no SHEET (equivalente a D. Lan√ßamento)
            date_sheet_col = None
            for c in df_sheet.columns:
                if _norm(c) in {"d lancamento", "data lancamento", "d lancamento data", "d lancamento.", "d. lancamento", "d.lancamento"}:
                    date_sheet_col = c
                    break
            if not date_sheet_col:
                st.error("‚ùå A aba **Sangria Everest** n√£o tem uma coluna de data equivalente a 'D. Lan√ßamento'. Nada foi alterado.")
                st.stop()
        
            # Detecta colunas de valor no SHEET (para formatar)
            valor_sheet_col  = None
            rateio_sheet_col = None
            for c in df_sheet.columns:
                if _norm(c) in {"valor lancamento", "valor lan√ßamento", "valor do lancamento", "valor de lancamento", "valor do lan√ßamento", "valor de lan√ßamento"}:
                    valor_sheet_col = c
                if _norm(c) in {"v rateio", "v. rateio", "valor rateio"}:
                    rateio_sheet_col = c
        
            # 1) Mant√©m SOMENTE as linhas cujas datas N√ÉO est√£o no arquivo (compara√ß√£o por string dd/mm/aaaa)
            sheet_dates_str = date_to_str(df_sheet[date_sheet_col])
            mask_remove = sheet_dates_str.isin(file_dates_str) & sheet_dates_str.ne("")
            kept = df_sheet.loc[~mask_remove].copy()
            removidas = int(mask_remove.sum())
        
            # 2) Alinhar as colunas do ARQUIVO √† ORDEM do SHEET
            df_insert = pd.DataFrame({col: (df_file[col] if col in df_file.columns else "") for col in header_sheet})
        
            # 3) Harmonizar a coluna de data inserida para dd/mm/aaaa (se existir nos dois lados)
            if date_file_col in df_file.columns and date_sheet_col in df_insert.columns:
                df_insert[date_sheet_col] = date_to_str(df_file[date_file_col])
        
            # 4) Formatar valores (v√≠rgula e 2 casas) p/ Valor Lan√ßamento e V. Rateio
            def to_str_comma(series_like):
                if pd.api.types.is_numeric_dtype(series_like):
                    nums = pd.to_numeric(series_like, errors="coerce").fillna(0.0)
                else:
                    nums = to_number_br(series_like)
                return nums.apply(lambda v: f"{float(v):.2f}".replace(".", ","))
        
            if valor_sheet_col:
                src_val = df_file[valor_file_col] if (valor_file_col and valor_file_col in df_file.columns) else df_insert.get(valor_sheet_col, "")
                df_insert[valor_sheet_col] = to_str_comma(src_val)
            if rateio_sheet_col:
                src_rat = df_file[rateio_file_col] if (rateio_file_col and rateio_file_col in df_file.columns) else df_insert.get(rateio_sheet_col, "")
                df_insert[rateio_sheet_col] = to_str_comma(src_rat)
        
            # 5) Final = OUTRAS DATAS (kept) + NOVAS (df_insert)
            df_final = pd.concat([kept, df_insert], ignore_index=True)
        
            # 6) Atualiza (mesmo layout: um bot√£o)
            # ‚è© Bot√£o super-r√°pido: deleta em FAIXAS + append √∫nico
            if st.button("üì• Atualizar Google Sheets Sangria Everest"):
                with st.spinner("üîÑ Enviando..."):
                    import pandas as _pd
            
                    # 1) Quais linhas do SHEET remover? (datas que est√£o no arquivo)
                    sheet_dates_str = date_to_str(df_sheet[date_sheet_col])  # 'dd/mm/aaaa'
                    mask_remove = sheet_dates_str.isin(file_dates_str) & sheet_dates_str.ne("")
                    rows_to_delete = [i + 2 for i, rm in enumerate(mask_remove) if bool(rm)]  # 1-based; +1 p/ header, +1 p/ 0-index
            
                    # 1a) Agrupa linhas cont√≠guas em FAIXAS para deletar por intervalo (muito mais r√°pido)
                    def compress_ranges(rows_1based):
                        if not rows_1based:
                            return []
                        rows = sorted(rows_1based)
                        start = prev = rows[0]
                        out = []
                        for r in rows[1:]:
                            if r == prev + 1:
                                prev = r
                            else:
                                out.append((start, prev))  # inclusive
                                start = prev = r
                        out.append((start, prev))
                        return out
            
                    ranges_1based = compress_ranges(rows_to_delete)
                    # Converte para √≠ndices 0-based/exclusivos exigidos pelo Sheets API
                    # Lembrando: linha 1 = header ‚Üí j√° n√£o entra; aqui est√£o linhas ‚â•2.
                    reqs = []
                    for (r1, r2) in sorted(ranges_1based, key=lambda t: t[0], reverse=True):
                        start_idx_0 = r1 - 1  # 0-based
                        end_idx_0   = r2      # exclusivo
                        reqs.append({
                            "deleteDimension": {
                                "range": {
                                    "sheetId": ws.id,           # id da worksheet (gid)
                                    "dimension": "ROWS",
                                    "startIndex": start_idx_0,
                                    "endIndex": end_idx_0
                                }
                            }
                        })
            
                    # 2) Dispara UM batch_update com todas as dele√ß√µes (ordem descendente evita shift)
                    if reqs:
                        ws.spreadsheet.batch_update({"requests": reqs})
            
                    # 3) Prepara as NOVAS linhas (alinhadas ao cabe√ßalho do SHEET)
                    df_insert = _pd.DataFrame({col: (df_file[col] if col in df_file.columns else "") for col in header_sheet})
            
                    # 3a) Data no padr√£o dd/mm/aaaa na coluna do SHEET
                    if date_file_col in df_file.columns and date_sheet_col in df_insert.columns:
                        df_insert[date_sheet_col] = date_to_str(df_file[date_file_col])
            
                    # 3b) Valores com v√≠rgula e 2 casas: Valor Lan√ßamento e V. Rateio
                    def to_str_comma(series_like):
                        if _pd.api.types.is_numeric_dtype(series_like):
                            nums = _pd.to_numeric(series_like, errors="coerce").fillna(0.0)
                        else:
                            nums = to_number_br(series_like)
                        return nums.apply(lambda v: f"{float(v):.2f}".replace(".", ","))
            
                    if valor_sheet_col:
                        src_val = (df_file[valor_file_col] if (valor_file_col and valor_file_col in df_file.columns)
                                   else df_insert.get(valor_sheet_col, ""))
                        df_insert[valor_sheet_col] = to_str_comma(src_val)
            
                    if rateio_sheet_col:
                        src_rat = (df_file[rateio_file_col] if (rateio_file_col and rateio_file_col in df_file.columns)
                                   else df_insert.get(rateio_sheet_col, ""))
                        df_insert[rateio_sheet_col] = to_str_comma(src_rat)
            
                    # 4) Append √öNICO das novas linhas (sem limpar o sheet)
                    novas_linhas = df_insert.fillna("").astype(str).values.tolist()

                    if novas_linhas:
                        ws.append_rows(novas_linhas, value_input_option="USER_ENTERED")
                    
                        # ‚¨áÔ∏è ADICIONE ESTE TRECHO
                        # Linhas novas come√ßam ap√≥s header + linhas mantidas
                        inicio = len(kept) + 2                # primeira linha nova (1=header)
                        fim    = inicio + len(novas_linhas) - 1
                    
                        # Usa os nomes reais no header_sheet detectados antes
                        if valor_sheet_col:
                            col_letter = _excel_col_letter(header_sheet.index(valor_sheet_col))
                            format_cell_range(ws, f"{col_letter}{inicio}:{col_letter}{fim}", ACCOUNTING_RS)
                        if rateio_sheet_col:
                            col_letter = _excel_col_letter(header_sheet.index(rateio_sheet_col))
                            format_cell_range(ws, f"{col_letter}{inicio}:{col_letter}{fim}", ACCOUNTING_RS)
                        # ‚¨ÜÔ∏è FIM DO TRECHO

                    st.success(
                        f"‚úÖAtualiza√ß√£o Concluida"
                    )


    
        # --- caso contr√°rio, fluxo Colibri original ---
        else:
            if "df_sangria" not in st.session_state:
                st.warning("‚ö†Ô∏è Primeiro fa√ßa o upload e o processamento na Aba 1.")
            else:
                df_final = st.session_state.df_sangria.copy()
    
                # Colunas na ordem do destino
                destino_cols = [
                    "Data", "Dia da Semana", "Loja", "C√≥digo Everest", "Grupo",
                    "C√≥digo Grupo Everest", "Funcion√°rio", "Hora", "Descri√ß√£o",
                    "Descri√ß√£o Agrupada", "Meio de recebimento", "Valor(R$)",
                    "M√™s", "Ano", "Duplicidade", "Sistema"
                ]
                faltantes = [c for c in destino_cols if c not in df_final.columns]
                if faltantes:
                    st.error(f"‚ùå Colunas ausentes para envio: {faltantes}")
                    st.stop()
    
                # Recalcula Duplicidade (Data + Hora + C√≥digo + Valor + Descri√ß√£o)
                df_final["Descri√ß√£o"] = (
                    df_final["Descri√ß√£o"].astype(str).str.strip().str.lower().str.replace(r"\s+", " ", regex=True)
                )
                data_key = pd.to_datetime(df_final["Data"], dayfirst=True, errors="coerce").dt.strftime("%Y-%m-%d")
                hora_key = pd.to_datetime(df_final["Hora"], errors="coerce").dt.strftime("%H:%M:%S")
                df_final["Valor(R$)"] = pd.to_numeric(df_final["Valor(R$)"], errors="coerce").fillna(0.0).round(2)
                valor_centavos = (df_final["Valor(R$)"].astype(float) * 100).round().astype(int).astype(str)
                desc_key = df_final["Descri√ß√£o"].fillna("").astype(str)
                df_final["Duplicidade"] = (
                    data_key.fillna("") + "|" +
                    hora_key.fillna("") + "|" +
                    df_final["C√≥digo Everest"].fillna("").astype(str) + "|" +
                    valor_centavos + "|" +
                    desc_key
                )
    
                # Inteiros opcionais
                for col in ["C√≥digo Everest", "C√≥digo Grupo Everest", "Ano"]:
                    df_final[col] = df_final[col].apply(lambda x: int(x) if pd.notnull(x) and str(x).strip() != "" else "")

                # Acessa a aba de destino
                aba_destino = planilha.worksheet("Sangria")
                valores_existentes = aba_destino.get_all_values()
                
                if not valores_existentes:
                    st.error("‚ùå A aba 'Sangria' est√° vazia. Crie o cabe√ßalho antes de enviar.")
                    st.stop()
                
                header_raw = valores_existentes[0]  # cabe√ßalho como est√° no Sheets (linha 1)
                
                # =========================
                # Normaliza√ß√£o/matching
                # =========================
                import unicodedata
                import re
                
                def _normalize_name(s: str) -> str:
                    s = str(s or "").strip()
                    # remove acentos
                    s = unicodedata.normalize("NFKD", s).encode("ASCII", "ignore").decode("ASCII")
                    s = s.lower()
                    # troca separadores por espa√ßo
                    s = re.sub(r"[_\-]+", " ", s)
                    # remove m√∫ltiplos espa√ßos
                    s = re.sub(r"\s+", " ", s).strip()
                    return s
                
                # nomes "can√¥nicos" (o que seu c√≥digo espera)
                destino_cols = [
                    "Data", "Dia da Semana", "Loja", "C√≥digo Everest", "Grupo",
                    "C√≥digo Grupo Everest", "Funcion√°rio", "Hora", "Descri√ß√£o",
                    "Descri√ß√£o Agrupada", "Meio de recebimento", "Valor(R$)",
                    "M√™s", "Ano", "Duplicidade", "Sistema"
                ]
                
                # vers√µes normalizadas dos can√¥nicos
                canon_norm = [_normalize_name(c) for c in destino_cols]
                
                # cria um √≠ndice do header existente por normaliza√ß√£o
                header_norm_map = {}  # normalizado -> nome original do sheet
                for col_name in header_raw:
                    header_norm_map[_normalize_name(col_name)] = col_name
                
                # tenta mapear cada can√¥nico para um nome real existente no sheet
                col_map = {}         # nome canonico -> nome existente no sheet (original)
                faltando = []        # can√¥nicos que n√£o foram encontrados
                for canon, canon_n in zip(destino_cols, canon_norm):
                    if canon_n in header_norm_map:
                        col_map[canon] = header_norm_map[canon_n]
                    else:
                        faltando.append(canon)
                
                if faltando:
                    # Diagn√≥stico amig√°vel
                    st.error("‚ùå O cabe√ßalho da aba 'Sangria' n√£o corresponde ao esperado.")
                    with st.expander("Ver diagn√≥stico"):
                        st.write("**Esperado (can√¥nico):**", destino_cols)
                        st.write("**Encontrado (linha 1 do Sheet):**", header_raw)
                        # quais equival√™ncias foram reconhecidas
                        reconhecidas = [f"{k} ‚Üí {v}" for k, v in col_map.items()]
                        if reconhecidas:
                            st.write("**Equival√™ncias reconhecidas:**", reconhecidas)
                        st.write("**Faltando no Sheet:**", faltando)
                        sobras = [h for h in header_raw if _normalize_name(h) not in set(canon_norm)]
                        if sobras:
                            st.write("**Colunas extras no Sheet (n√£o usadas):**", sobras)
                
                    # üëâ BOT√ÉO OPCIONAL para corrigir s√≥ o cabe√ßalho (mantendo dados)
                    # Use APENAS se tiver certeza de que as linhas abaixo j√° est√£o na ordem das colunas can√¥nicas!
                    if st.button("‚ö†Ô∏è Corrigir cabe√ßalho (linha 1) para o padr√£o esperado"):
                        # atualiza somente a linha 1 com os nomes can√¥nicos
                        aba_destino.update("A1", [destino_cols])
                        st.success("‚úÖ Cabe√ßalho atualizado. Rode o envio novamente.")
                    st.stop()
                
                # Se chegou aqui, todas as colunas can√¥nicas existem no Sheet (mesmo que com outro nome/ordem)
                # Vamos alinhar o DataFrame √† ORDEM ATUAL do Sheet, preservando layout existente.
                # Monta a ordem final de colunas para enviar, com base no header do Sheet:
                # - se a coluna do sheet est√° entre as que mapeiam para can√¥nicas, usamos o nome can√¥nico
                # - se for uma coluna extra do sheet, vamos preench√™-la com vazio para as novas linhas
                sheet_order_canon = []       # nomes CAN√îNICOS na ordem do sheet
                sheet_order_real = []        # nomes REAIS do sheet na mesma ordem (√∫til para log)
                sheet_extras = []
                
                norm_to_canon = {_normalize_name(v): k for k, v in col_map.items()}  # nome real(normalizado) -> can√¥nico
                
                for h in header_raw:
                    hn = _normalize_name(h)
                    if hn in norm_to_canon:
                        sheet_order_canon.append(norm_to_canon[hn])  # can√¥nico correspondente
                        sheet_order_real.append(h)                   # nome real no sheet
                    else:
                        sheet_extras.append(h)
                
                # Reindexa df_final para a ordem do Sheet:
                # - primeiras colunas: os can√¥nicos na ordem em que aparecem no sheet
                # - para colunas extra do sheet (que n√£o existem no df_final), preenche com ""
                df_final = df_final.copy()
                
                for extra in sheet_extras:
                    # cria coluna vazia para cobrir colunas excedentes do sheet (se houverem)
                    df_final[extra] = ""
                
                # O df deve conter todas as colunas can√¥nicas; garantimos isso:
                for c in destino_cols:
                    if c not in df_final.columns:
                        df_final[c] = ""
                
                # Monta a lista de colunas finais na ordem do sheet:
                colunas_finais = []
                for h in header_raw:
                    hn = _normalize_name(h)
                    if hn in norm_to_canon:
                        # pega o can√¥nico correspondente
                        ccanon = norm_to_canon[hn]
                        colunas_finais.append(ccanon)
                    else:
                        # coluna extra do sheet
                        colunas_finais.append(h)
                
                # aplica a ordem
                df_final = df_final[colunas_finais].fillna("")
                
                # =========================
                # Duplicidade (usando a coluna 'Duplicidade' CAN√îNICA)
                # =========================
                # encontra a posi√ß√£o da coluna 'Duplicidade' na ORDEM DO SHEET
                try:
                    dup_idx = header_raw.index(col_map["Duplicidade"])  # nome real do sheet para 'Duplicidade'
                except Exception:
                    # fallback: tenta achar 'Duplicidade' literal no header
                    try:
                        dup_idx = header_raw.index("Duplicidade")
                    except ValueError:
                        st.error("‚ùå Cabe√ßalho n√£o cont√©m a coluna 'Duplicidade'.")
                        st.stop()
                
                # ‚ö†Ô∏è CHAVES J√Å EXISTENTES (apenas do Google Sheets!)
                dados_existentes = set([
                    linha[dup_idx] for linha in valores_existentes[1:]
                    if len(linha) > dup_idx and linha[dup_idx] != ""
                ])
                # üîΩ AQUI: garanta que Valor(R$) √© n√∫mero antes de virar lista
                df_final["Valor(R$)"] = pd.to_numeric(df_final["Valor(R$)"], errors="coerce").fillna(0.0)
                # ‚úÖ Ignorar duplicidade interna do arquivo, checar s√≥ com o Sheets
                novos_dados, duplicados_sheet = [], []
                for linha in df_final.values.tolist():
                    chave = linha[dup_idx]
                    if chave in dados_existentes:
                        duplicados_sheet.append(linha)
                    else:
                        novos_dados.append(linha)
                
                if st.button("üì• Atualizar Google Sheets Sangria"):
                    with st.spinner("üîÑ Enviando..."):
                        if novos_dados:
                            aba_destino.append_rows(novos_dados, value_input_option="USER_ENTERED")
                
                            # Descobre √≠ndices (1-based) das colunas Data e Valor para formatar
                            try:
                                col_data_letter = chr(ord('A') + header_raw.index(col_map["Data"]))
                            except Exception:
                                col_data_letter = None
                
                            try:
                                col_valor_letter = chr(ord('A') + header_raw.index(col_map["Valor(R$)"]))
                            except Exception:
                                col_valor_letter = None
                

                            inicio = len(valores_existentes) + 1
                            fim = inicio + len(novos_dados) - 1
                            
                            if fim >= inicio:
                                # Data (mant√©m como est√°)
                                if col_data_letter:
                                    format_cell_range(
                                        aba_destino, f"{col_data_letter}{inicio}:{col_data_letter}{fim}",
                                        CellFormat(numberFormat=NumberFormat(type="DATE", pattern="dd/mm/yyyy"))
                                    )
                                # Valor(R$) em CONT√ÅBIL com R$
                                if col_valor_letter:
                                    format_cell_range(
                                        aba_destino, f"{col_valor_letter}{inicio}:{col_valor_letter}{fim}",
                                        ACCOUNTING_RS   # ‚úÖ use o mesmo nome definido
                                    )

                
                            st.success(f"‚úÖ {len(novos_dados)} registros enviados!")
                        if duplicados_sheet:
                            st.warning("‚ö†Ô∏è Alguns registros j√° existiam no Google Sheets e n√£o foram enviados.")
